import openai
from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
import sqlite3
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity #scikit-learn (–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏)
import logging
from datetime import datetime
import random


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

client = openai.OpenAI(
    api_key=""
)

positive_gifs = [
    "C:/Users/–ö–æ—Å—Ç—è/PycharmProjects/Latoken/dancing-cat-dance.gif",
    "C:/Users/–ö–æ—Å—Ç—è/PycharmProjects/Latoken/engoy.gif",
    "C:/Users/–ö–æ—Å—Ç—è/PycharmProjects/Latoken/really-well-done-thomas-elms.gif",
    "C:/Users/–ö–æ—Å—Ç—è/PycharmProjects/Latoken/shreks-meme.gif",
    "C:/Users/–ö–æ—Å—Ç—è/PycharmProjects/Latoken/kitty-smiley-kitty.gif"
]

negative_gifs = [
    "C:/Users/–ö–æ—Å—Ç—è/PycharmProjects/Latoken/sad1.gif",
    "C:/Users/–ö–æ—Å—Ç—è/PycharmProjects/Latoken/sad2.gif",
    "C:/Users/–ö–æ—Å—Ç—è/PycharmProjects/Latoken/sad3.gif",
    "C:/Users/–ö–æ—Å—Ç—è/PycharmProjects/Latoken/sad4.gif",
    "C:/Users/–ö–æ—Å—Ç—è/PycharmProjects/Latoken/sad5.gif"
]


current_positive_gif_index = 0
current_negative_gif_index = 0


def initialize_database():
    conn = sqlite3.connect("rag_database.db")
    cursor = conn.cursor()
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS fragments (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        category TEXT,
        text TEXT,
        embedding BLOB
    )
    """)
    conn.commit()
    conn.close()


def create_embeddings(texts):
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ texts –Ω–µ –ø—É—Å—Ç–æ–π –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏
        if not texts or not all(isinstance(text, str) and text.strip() for text in texts):
            logger.warning("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π —Ç–µ–∫—Å—Ç.")
            return [np.zeros(1536) for _ in texts]  
        response = client.embeddings.create(
            model="text-embedding-ada-002",  
            input=texts
        )
        return [item.embedding for item in response.data]
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
        return [np.zeros(1536) for _ in texts]  


def load_and_store_data(file_path):
    conn = sqlite3.connect("rag_database.db")
    cursor = conn.cursor()
    cursor.execute("DELETE FROM fragments")
    conn.commit()
    with open(file_path, "r", encoding="utf-8") as file:
        lines = file.readlines()
    current_category = None
    batch = []
    for line in lines:
        if line.startswith("[") and line.endswith("]\n"):
            current_category = line.strip()[1:-1]
        elif line.strip():
            batch.append((current_category, line.strip()))
            if len(batch) >= 50:
                process_batch(cursor, batch)
                batch = []
    if batch:
        process_batch(cursor, batch)
    conn.commit()
    conn.close()

def process_batch(cursor, batch):
    categories, texts = zip(*batch)
    embeddings = create_embeddings(texts)
    cursor.executemany("""
    INSERT INTO fragments (category, text, embedding)
    VALUES (?, ?, ?)
    """, [(cat, txt, str(list(emb))) for cat, txt, emb in zip(categories, texts, embeddings)])


def retrieve_relevant_fragments(query, category=None, top_k=25):
    query_embedding = create_embeddings([query])[0]
    conn = sqlite3.connect("rag_database.db")
    cursor = conn.cursor()
    if category:
        cursor.execute("SELECT category, text, embedding FROM fragments WHERE category=?", (category,))
    else:
        cursor.execute("SELECT category, text, embedding FROM fragments")
    rows = cursor.fetchall()
    conn.close()
    results = []
    for category, text, emb in rows:
        emb_array = np.array(eval(emb))
        similarity = cosine_similarity([query_embedding], [emb_array])[0][0]
        results.append((category, text, similarity))
    categorized_results = {}
    for category, text, similarity in sorted(results, key=lambda x: x[2], reverse=True):
        if category not in categorized_results:
            categorized_results[category] = []
        if len(categorized_results[category]) < top_k:
            categorized_results[category].append((text, similarity))
    return categorized_results

def generate_response(query, context_data):
    try:
        system_prompt = (
            "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º Latoken. –û—Ç–≤–µ—á–∞–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."
            "–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ - —Å–æ–æ–±—â–∏ –æ–± —ç—Ç–æ–º –≤–µ–∂–ª–∏–≤–æ –∏ –Ω–µ –≥–æ–≤–æ—Ä–∏ –ø—Ä–æ —á—Ç–æ-—Ç–æ –º–∏–º–æ Latokena"
            "–í—Å–µ–≥–¥–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π –≤—Å–µ —Å—Å—ã–ª–∫–∏ –ø–æ —Ç–µ–º–µ."
            "–í—Å–µ–≥–¥–∞ —Å—Ç–∞–≤—å —ç–º–æ–¥–∑–∏ —Ç–∞–º, –≥–¥–µ —ç—Ç–æ –±—É–¥–µ—Ç —É–º–µ—Å—Ç–Ω–æ –∏ –≤ —Ç–µ–º—É"
            "–°—Å—ã–ª–∫–∏ –≤—Å–µ–≥–¥–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–π –≤ —Å–ª–æ–≤–∞"
            "–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–ª–∏ –æ–Ω–∞ –Ω–∏–∫–∞–∫ –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ Latoken  - –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å–∫–∞–∂–∏ '–ò–∑–≤–∏–Ω–∏—Ç–µ'"
        )
        context_parts = []
        for category, fragments in context_data.items():
            context_parts.append(f"=== {category} ===")
            for text, _ in fragments:
                context_parts.append(text)
        full_context = "\n".join(context_parts)
        max_context_length = 3000
        if len(full_context) > max_context_length:
            full_context = full_context[:max_context_length] + "\n[...]"
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{full_context}\n–í–æ–ø—Ä–æ—Å: {query}"}
            ],
            max_tokens=1000,
            temperature=0.7,
            top_p=0.9
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
        return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞."

def generate_test_question(last_query, context_data):
    try:

        context_parts = []
        for category, fragments in context_data.items():
            context_parts.append(f"=== {category} ===")
            for text, _ in fragments:
                context_parts.append(text)
        full_context = "\n".join(context_parts)
        system_prompt = (
            "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é —Ç–µ—Å—Ç–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."
            "–í–æ–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –∑–∞–ø—Ä–æ—Å—É –∏ —Å–ª–æ–∂–Ω—ã–º, –Ω–æ —á–µ—Ç–∫–∏–º."
            "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –æ–¥–∏–Ω –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∏ –¥–≤–∞ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞ –æ—Ç–≤–µ—Ç–∞."
            "–í–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å—Ç—Ä–æ–≥–æ 3, –Ω–µ –±–æ–ª—å—à–µ, –Ω–∏ –º–µ–Ω—å—à–µ. –°–ª–µ–¥–∏ –∑–∞ —ç—Ç–∏–º."
            "–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: —Å–Ω–∞—á–∞–ª–∞ –≤–æ–ø—Ä–æ—Å, –∑–∞—Ç–µ–º —Ç—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –æ—Ç–≤–µ—Ç–∞, —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–µ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–æ–π."
            "–¢–∞–∫ –∂–µ –Ω—É–º–µ—Ä–æ–≤–∫–∞ –¥–æ–ª–∂–Ω–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å"
        )
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"–ü–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—Ä–æ—Å: {last_query}\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{full_context}"}
            ],
            max_tokens=150,
            temperature=0.7,
            top_p=0.9
        )
        response_lines = response.choices[0].message.content.strip().split("\n")
        if len(response_lines) < 4:
            logger.error("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞ –∏ –æ—Ç–≤–µ—Ç–æ–≤.")
            return None, None, None
        question = response_lines[0]
        options = response_lines[2:5]  
        correct_answer = options[0]
        random.shuffle(options)
        correct_index = options.index(correct_answer)
        return question, options, correct_index  
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞: {e}")
        return None, None, None

async def toggle_test(update: Update, context: ContextTypes.DEFAULT_TYPE):
    current_state = context.user_data.get("test_mode", True)
    context.user_data["test_mode"] = not current_state
    state_text = "–≤–∫–ª—é—á–µ–Ω" if not current_state else "–≤—ã–∫–ª—é—á–µ–Ω"
    logger.info(f"–†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è {state_text}")
    await update.message.reply_text(
        f"–†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è {state_text}.",
        parse_mode="Markdown"
    )

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [
        ["üìö –†–∞—Å—Å–∫–∞–∂–∏ –≤—Å–µ –æ Latoken", "üèÜ –û —Ö–∞–∫–∞—Ç–æ–Ω–µ"],  # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∫–Ω–æ–ø–æ–∫
        ["ü§ù –ö—É–ª—å—Ç—É—Ä–∞ Latoken", "üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"]  # –í—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞ –∫–Ω–æ–ø–æ–∫
    ]
    reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
    await update.message.reply_text(
        "üëã *–ü—Ä–∏–≤–µ—Ç!* –Ø ‚Äî —Ç–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º Latoken. üòä\n"
        "–ù–∞–∂–º–∏ –æ–¥–Ω—É –∏–∑ –∫–Ω–æ–ø–æ–∫ –∏–ª–∏ –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º –≤–∏–¥–µ.\n"
        "*–¢—ã —Å–µ–π—á–∞—Å –≤ —Ä–µ–∂–∏–º–µ '—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è'.*\n"
        "–í —ç—Ç–æ–º —Ä–µ–∂–∏–º–µ, –ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –∑–∞–¥–∞—à—å –≤–æ–ø—Ä–æ—Å, –±—É–¥–µ—Ç –ø—Ä–æ—Ö–æ–¥–∏—Ç—å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ.\n"
        "–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —á—Ç–æ –±—ã —Ç–µ–±—è –Ω–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞, –Ω–∞–∂–º–∏ –Ω–∞ –∫–Ω–æ–ø–∫—É *'üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è'*, –∫–æ—Ç–æ—Ä–∞—è —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∞ –≤ –º–µ–Ω—é –±–æ—Ç–∞.",
        reply_markup=reply_markup,
        parse_mode="Markdown"
    )

async def send_gif(update: Update, is_correct: bool):
    global current_positive_gif_index, current_negative_gif_index

    if is_correct:
        gifs = positive_gifs
        current_index = current_positive_gif_index
        current_positive_gif_index = (current_positive_gif_index + 1) % len(positive_gifs)  # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å
    else:
        gifs = negative_gifs
        current_index = current_negative_gif_index
        current_negative_gif_index = (current_negative_gif_index + 1) % len(negative_gifs)  # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å

    gif_url = gifs[current_index]
    await update.message.reply_animation(gif_url)

def format_response(response):
    response = response.replace("[–ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ —Ö–∞–∫–∞—Ç–æ–Ω–µ]", "üìñ [–ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ —Ö–∞–∫–∞—Ç–æ–Ω–µ]")
    response = response.replace("[–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç Latoken]", "üåê [–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç Latoken]")
    response = response.replace("### ", "üìå ")  # –î–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    response = response.replace("## ", "üîπ ")  # –î–ª—è –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    response = response.replace("# ", "üî∏ ")  # –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    response = response.replace("- –ö—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç:", "üîç *–ö—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç:*")
    response = response.replace("- –ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ:", "üìö *–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ:*")
    response = response.replace("- –¶–∏—Ç–∞—Ç—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:", "üìÑ *–¶–∏—Ç–∞—Ç—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:*")
    response = response.replace("- –°—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã:", "üîó *–°—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã:*")
    return response

def load_context_from_file(file_path):

    context_data = {}
    current_category = None

    with open(file_path, "r", encoding="utf-8") as file:
        lines = file.readlines()

    for line in lines:
        line = line.strip()
        if line.startswith("[") and line.endswith("]"):

            current_category = line[1:-1]
            context_data[current_category] = []
        elif line and current_category:

            text = line
            embedding = create_embeddings([text])[0]
            context_data[current_category].append({"text": text, "embedding": embedding})

    return context_data

def check_if_knows_answer(query):
    try:

        query_embedding = create_embeddings([query])[0]

        conn = sqlite3.connect("rag_database.db")
        cursor = conn.cursor()
        cursor.execute("SELECT embedding FROM fragments")
        rows = cursor.fetchall()
        conn.close()

        similarities = []
        for row in rows:
            fragment_embedding = np.array(eval(row[0]))
            similarity = cosine_similarity([query_embedding], [fragment_embedding])[0][0]
            similarities.append(similarity)

        max_similarity = max(similarities) if similarities else 0.0

        threshold = 0.7  
        return max_similarity >= threshold
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∑–Ω–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞: {e}")
        return False

def contains_uncertainty_phrases(response):

    uncertainty_phrases = [
        "–∏–∑–≤–∏–Ω–∏—Ç–µ",
        "–ø—Ä–æ—Å—Ç–∏",
        "–Ω–µ —É–∫–∞–∑–∞–Ω–æ",
        "–Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
        "–Ω–µ –º–æ–≥—É —Å–∫–∞–∑–∞—Ç—å",
        "–Ω–µ –∑–Ω–∞—é",
        "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç",
        "–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç"
    ]

    response_lower = response.lower()
    for phrase in uncertainty_phrases:
        if phrase in response_lower:
            return True
    return False


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text.lower()
    logger.info(f"[{datetime.now()}] –ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: {user_message}")


    if user_message == "–Ω–∞–∑–∞–¥":
        context.user_data["testing"] = False
        keyboard = [
            ["üìö –†–∞—Å—Å–∫–∞–∂–∏ –≤—Å–µ –æ Latoken", "üèÜ –û —Ö–∞–∫–∞—Ç–æ–Ω–µ"],
            ["ü§ù –ö—É–ª—å—Ç—É—Ä–∞ Latoken", "üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"]
        ]
        reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
        await update.message.reply_text(
            "üîô –í—ã –≤—ã—à–ª–∏ —Å –≤–æ–ø—Ä–æ—Å–∞.",
            reply_markup=reply_markup,
            parse_mode="Markdown"
        )
        return

    if user_message == "üîÑ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è":
        await toggle_test(update, context)
        return


    if context.user_data.get("testing"):
        correct_index = context.user_data["correct_index"]
        options = context.user_data["options"]  
        if user_message.isdigit():
            selected_index = int(user_message) - 1  
            if 0 <= selected_index < len(options):
                is_correct = selected_index == correct_index
                if is_correct:
                    response = "üéâ *–û—Ç–ª–∏—á–Ω–æ!* –¢—ã –∞–±—Å–æ–ª—é—Ç–Ω–æ –ø—Ä–∞–≤!\n" \
                               f"–ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç: _{options[correct_index]}_"
                else:
                    response = "üòï *–ù–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ.*\n" \
                               f"–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: _{options[correct_index]}_"
                context.user_data["testing"] = False
                keyboard = [
                    ["üìö –†–∞—Å—Å–∫–∞–∂–∏ –≤—Å–µ –æ Latoken", "üèÜ –û —Ö–∞–∫–∞—Ç–æ–Ω–µ"],
                    ["ü§ù –ö—É–ª—å—Ç—É—Ä–∞ Latoken", "üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"]
                ]
                reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
                await update.message.reply_text(response, reply_markup=reply_markup, parse_mode="Markdown")
                await send_gif(update, is_correct)
                return
        await update.message.reply_text("ü§î –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏ –Ω–æ–º–µ—Ä –æ—Ç–≤–µ—Ç–∞ –∏–ª–∏ –Ω–∞–ø–∏—à–∏ '–Ω–∞–∑–∞–¥', —á—Ç–æ–±—ã –≤—ã–π—Ç–∏.")
        return


    if user_message == "–≤—Å–µ –æ latoken":
        query = "–†–∞—Å—Å–∫–∞–∂–∏ –æ –∫–æ–º–ø–∞–Ω–∏–∏ Latoken"
        category = None
    elif user_message == "–≤—Å–µ –æ —Ö–∞–∫–∞—Ç–æ–Ω–µ":
        query = "–†–∞—Å—Å–∫–∞–∂–∏ –æ —Ö–∞–∫–∞—Ç–æ–Ω–µ"
        category = "–•–∞–∫–∞—Ç–æ–Ω"
    elif user_message == "–≤—Å–µ –æ –∫—É–ª—å—Ç—É—Ä–µ latoken":
        query = "–†–∞—Å—Å–∫–∞–∂–∏ –æ –∫—É–ª—å—Ç—É—Ä–µ Latoken"
        category = "–ö—É–ª—å—Ç—É—Ä–∞"
    else:
        query = user_message
        category = None

    expanded_query = expand_query(query)
    relevant_fragments = retrieve_relevant_fragments(expanded_query, category)
    generating_message = await update.message.reply_text("‚è≥ –ë–æ—Ç –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç... [0%]")
    try:
        for progress in range(10, 110, 10):  # –û—Ç 10% –¥–æ 100%
            if progress < 100:
                await context.bot.edit_message_text(
                    chat_id=update.message.chat_id,
                    message_id=generating_message.message_id,
                    text=f"‚è≥ –ë–æ—Ç –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç... [{progress}%]"
                )


        gpt_response = generate_response(expanded_query, relevant_fragments)
        formatted_response = format_response(gpt_response)


        await context.bot.delete_message(chat_id=update.message.chat_id, message_id=generating_message.message_id)

        await update.message.reply_text(formatted_response, parse_mode="Markdown")

        if context.user_data.get("test_mode", True):
            if contains_uncertainty_phrases(gpt_response):
                await update.message.reply_text(
                    "üòî –ù–µ –º–æ–≥—É –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–∞—à–∏ –∑–Ω–∞–Ω–∏—è, —Ç–∞–∫ –∫–∞–∫ —Å–∞–º –Ω–µ –∑–Ω–∞—é –Ω–∞ —ç—Ç–æ –æ—Ç–≤–µ—Ç.",
                    parse_mode="Markdown"
                )
                await send_gif(update, is_correct=False)  # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥—Ä—É—Å—Ç–Ω—É—é –≥–∏—Ñ–∫—É
                return

            test_question, options, correct_index = generate_test_question(query, relevant_fragments)
            if test_question and options:
                options_text = "\n".join([f"{i + 1}. {option}" for i, option in enumerate(options)])
                message_text = (
                    f"üß† *–¢–µ—Å—Ç–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å:* {test_question}\n"
                    f"üìù *–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤:*\n{options_text}\n"
                    "üéØ –í—ã–±–µ—Ä–∏ –Ω–æ–º–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∏–ª–∏ –Ω–∞–ø–∏—à–∏ '–Ω–∞–∑–∞–¥', —á—Ç–æ–±—ã –≤—ã–π—Ç–∏:"
                )
                keyboard = [[str(i + 1)] for i in range(len(options))]
                keyboard.append(["–Ω–∞–∑–∞–¥"])  # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É "–Ω–∞–∑–∞–¥"
                reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
                context.user_data["testing"] = True
                context.user_data["correct_index"] = correct_index
                context.user_data["options"] = options
                await update.message.reply_text(message_text, reply_markup=reply_markup, parse_mode="Markdown")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        await context.bot.delete_message(chat_id=update.message.chat_id, message_id=generating_message.message_id)
        await update.message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞.", parse_mode="Markdown")


def expand_query(query):
    keywords_map = {
        "–ø—Ä–æ—Ü–µ—Å—Å –Ω–∞–π–º–∞": ["—Ä–µ–∫—Ä—É—Ç–∏–Ω–≥", "–∏–Ω—Ç–µ—Ä–≤—å—é", "—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"],
        "—Ö–∞–∫–∞—Ç–æ–Ω": ["—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ", "–ø—Ä–∏–∑—ã", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "—Ñ–æ—Ä–º–∞—Ç", "—É—á–∞—Å—Ç–∏–µ"],
        "–∫—É–ª—å—Ç—É—Ä–∞": ["—Ü–µ–Ω–Ω–æ—Å—Ç–∏", "—Ç—Ä–∞–¥–∏—Ü–∏–∏", "–∫–æ–º–∞–Ω–¥–Ω–∞—è —Ä–∞–±–æ—Ç–∞"]
    }
    expanded = query
    for main_term, related in keywords_map.items():
        if main_term in query:
            expanded += " " + " ".join(related)
    return expanded

async def restart(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # –í—ã–∑—ã–≤–∞–µ–º —Ç–æ—Ç –∂–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª, —á—Ç–æ –∏ –≤ /start
    await start(update, context)


def main():
    try:
        initialize_database()
        context_data = load_and_store_data("context2.txt")  # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
        token = ""
        app = ApplicationBuilder().token(token).build()


        app.bot_data["context_data"] = context_data


        app.add_handler(CommandHandler("start", start))
        app.add_handler(CommandHandler("restart", restart))  # –ù–æ–≤—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
        app.add_handler(CommandHandler("toggle_test", toggle_test))
        app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
        commands = [
            ("start", "–ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã"),
            ("restart", "–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞"),  # –ù–æ–≤–∞—è –∫–æ–º–∞–Ω–¥–∞
        ]
        app.bot.set_my_commands(commands)

        logger.info("–ë–æ—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω")
        app.run_polling()
    except Exception as e:
        logger.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":

    main()

